# ANPR System - Quick Setup Guide

## ğŸ“‹ Prerequisites

- Python 3.8 or higher
- Git
- Webcam or video files for testing
- (Optional) CUDA-capable GPU for better performance

## ğŸš€ Quick Start (Fresh Installation)

### Step 1: Clone the Repository

```bash
git clone <your-repository-url>
cd ANPR
```

### Step 2: Install the Package

**Option A: Using setup.py (Recommended for Development)**
```bash
pip install -e .
```
This installs the package in "editable" mode with all dependencies.

**Option B: Using requirements.txt (Simpler)**
```bash
pip install -r requirements.txt
```

**Optional Extras:**
```bash
# For better OCR performance (optional)
pip install -e .[fast]

# For development tools (optional)
pip install -e .[dev]
```

### Step 3: Verify Essential Files

After cloning, verify that these files exist:

#### âœ… **Production Models** (in `models/application_runner/`)
- `best.pt` (~6MB) - YOLO11n ANPR detection model
- `best_crnn_model_epoch125_acc0.9010.pth` (~4MB) - CRNN OCR v7 model

#### âœ… **Configuration Files** (in `config/`)
- `data.yaml` - YOLO data configuration
- `deployment_config.json` - Deployment settings
- `custom_hyp_imbalanced.yaml` - Training hyperparameters

#### âœ… **Data Files**
- `data/processed/all_chars.txt` - OCR character set
- `data/Input/*.mp4` - Demo video files (optional)

#### âœ… **Source Code** (in `src/`)
- `main.py` - Main application
- All Python files in subdirectories

### Step 4: Verify Setup

Run this verification script:

```bash
python -c "
from pathlib import Path
import sys

print('ğŸ” Verifying ANPR Setup...\n')

# Check models
models_ok = True
model_files = [
    'models/application_runner/best.pt',
    'models/application_runner/best_crnn_model_epoch125_acc0.9010.pth'
]
for model in model_files:
    exists = Path(model).exists()
    status = 'âœ…' if exists else 'âŒ'
    print(f'{status} {model}')
    if not exists:
        models_ok = False

# Check data
data_file = 'data/processed/all_chars.txt'
data_ok = Path(data_file).exists()
status = 'âœ…' if data_ok else 'âŒ'
print(f'{status} {data_file}')

# Check config
config_ok = Path('config/data.yaml').exists()
status = 'âœ…' if config_ok else 'âŒ'
print(f'{status} config/data.yaml')

print()
if models_ok and data_ok and config_ok:
    print('âœ… Setup verification PASSED! Ready to run.')
    sys.exit(0)
else:
    print('âŒ Setup verification FAILED! Some files are missing.')
    print('   Make sure you cloned with: git clone --depth 1 <url>')
    sys.exit(1)
"
```

### Step 5: Run the Application

```bash
# Method 1: Direct execution
python src/main.py

# Method 2: If installed with setup.py
anpr
```

The application will:
1. Automatically load models from `models/application_runner/`
2. Create `outputs/` and `logs/` directories if they don't exist
3. Launch the PyQt5 GUI interface

## ğŸ“ Repository Structure (What's Tracked)

### âœ… **Tracked Files** (Included in Git)

```
ANPR/
â”œâ”€â”€ README.md                              # Documentation
â”œâ”€â”€ SETUP_GUIDE.md                         # This file
â”œâ”€â”€ requirements.txt                       # Python dependencies
â”œâ”€â”€ setup.py                              # Package setup
â”œâ”€â”€ .gitignore                            # Git ignore rules
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ application_runner/               # â­ Production models (~10MB total)
â”‚       â”œâ”€â”€ best.pt                       # YOLO11n detection
â”‚       â””â”€â”€ best_crnn_model_epoch125_acc0.9010.pth  # CRNN v7 OCR
â”‚
â”œâ”€â”€ config/                               # Configuration files
â”‚   â”œâ”€â”€ data.yaml
â”‚   â”œâ”€â”€ deployment_config.json
â”‚   â””â”€â”€ custom_hyp_imbalanced.yaml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Input/                            # Demo videos (optional)
â”‚   â”‚   â””â”€â”€ *.mp4
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ all_chars.txt                 # OCR character set
â”‚
â”œâ”€â”€ src/                                  # Source code
â”‚   â”œâ”€â”€ main.py                           # Main application
â”‚   â”œâ”€â”€ models/                           # Model loaders
â”‚   â”œâ”€â”€ training/                         # Training scripts
â”‚   â””â”€â”€ utils/                            # Utilities
â”‚
â””â”€â”€ scripts/                              # Utility scripts
    â”œâ”€â”€ evaluate.py
    â””â”€â”€ demo.py
```

### âŒ **Ignored Files** (Not in Git)

```
ANPR/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ detection/                        # âŒ Large training checkpoints (~500MB+)
â”‚   â””â”€â”€ ocr/                             # âŒ Large training checkpoints (~500MB+)
â”‚
â”œâ”€â”€ data/                                 # âŒ Most data files
â”‚   â”œâ”€â”€ raw/                             # Raw input data
â”‚   â”œâ”€â”€ annotation/                       # Training annotations
â”‚   â”œâ”€â”€ scraped_images/                   # Downloaded images
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ outputs/                              # âŒ Generated at runtime
â”œâ”€â”€ logs/                                 # âŒ Generated at runtime
â”œâ”€â”€ Trash/                                # âŒ Temporary files
â””â”€â”€ __pycache__/                         # âŒ Python cache
```

## ğŸ”§ Configuration

### Model Paths (Automatic)

The system uses **automatic path detection**:

```python
# In src/main.py
PROJECT_ROOT = Path(__file__).resolve().parent.parent

YOLO_MODEL_PATH = PROJECT_ROOT / "models" / "application_runner" / "best.pt"
CRNN_MODEL_PATH = PROJECT_ROOT / "models" / "application_runner" / "best_crnn_model_epoch125_acc0.9010.pth"
```

**No manual path configuration needed!** Works on:
- âœ… Windows
- âœ… Linux
- âœ… macOS

### Settings in GUI

All settings can be adjusted through the GUI:
- Confidence thresholds
- Camera resolution
- Detection modes (Real-time, Parking, Zone-based)
- Frame processing rate

## ğŸ¯ Usage Modes

### 1. **Camera Mode**
- Live detection from webcam
- Adjustable resolution and FPS
- Real-time processing

### 2. **Video File Mode**
- Process pre-recorded videos
- Playback speed control (0.5x - 6x)
- Seek forward/backward
- Zone-based detection

### 3. **Detection Modes**
- **Real-time Detection**: Process all detected plates
- **Parking Vehicle Detection**: Detect stationary vehicles
- **Zone-based Detection**: Define entry/exit zones

## ğŸ“Š Model Information

### YOLO11n ANPR Detection
- **File**: `best.pt` (~6MB)
- **Performance**: 90.3% mAP@0.5
- **Classes**: Car, Motorcycle, Number_Plate
- **Speed**: 80-120 FPS (RTX 3060)

### CRNN v7 OCR
- **File**: `best_crnn_model_epoch125_acc0.9010.pth` (~4MB)
- **Accuracy**: 90.10%
- **Character Set**: 36 characters (0-9, A-Z, blank)
- **Input**: 256x64 RGB images

## ğŸ› Troubleshooting

### Issue: Models not found
**Solution**: Verify files exist in `models/application_runner/`

### Issue: Camera not detected
**Solution**: Click "ğŸ” Detect Cameras" button in GUI

### Issue: Low detection accuracy
**Solution**: Adjust confidence thresholds in Settings panel

### Issue: Import errors
**Solution**: Ensure all dependencies are installed:
```bash
pip install -r requirements.txt
```

## ğŸ“ Output Files

Generated in `outputs/` directory:
- `car_PLATENUMBER_timestamp_conf.jpg` - Detected vehicles with plates
- `debug_*.jpg` - Debug frames
- `detection_log.jsonl` - JSON log of all detections

## ğŸ”„ Updating the Repository

After pulling updates:

```bash
git pull origin main
pip install -r requirements.txt  # Update dependencies if changed
python src/main.py               # Run the application
```

## ğŸ’¾ Repository Size

**Total Repository Size**: ~15-20 MB
- Production models: ~10 MB
- Source code: ~1 MB
- Configuration: <1 MB
- Demo videos: ~5 MB (optional)

**Note**: Training checkpoints are NOT included (would add ~1GB+)

## ğŸ“ For Development

If you want to train models or access full training history:

1. Download full model checkpoints separately
2. Place in `models/detection/` and `models/ocr/`
3. Use training scripts in `src/training/`

## ğŸ“§ Support

For issues or questions:
- Check the main `README.md`
- Review this setup guide
- Check the troubleshooting section

---

**Happy License Plate Recognition! ğŸš—ğŸ“¸**

